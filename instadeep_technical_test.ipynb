{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39f936b8-7bf7-4f3e-ae3d-3d73b76611b5",
   "metadata": {},
   "source": [
    "# **Instadeep technical test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8285d1c2-26db-4f62-9c66-cdfc8bcb6ff8",
   "metadata": {},
   "source": [
    "In this notebook we wanted to demonstrate the different methods to embed data, perform similarity search, and summarize documents, using LangChain with Hugging Face models or OpenAI models. \n",
    "\n",
    "* Vector database: We used ChromaDB as database for embeddings.\n",
    "* Embedding data: We used Hugging Face's sentence transformers (We can also use OpenAI's embedding models).\n",
    "* Recommendation of 3 papers: We used both ChromaDB's similarity search and LangChain's retrievers.\n",
    "* Paper summarization: We used OpenAI's GPT 3.5 Turbo as a chat LLM, and both map-reduce and refine methods for summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba894ca5-a4ac-4889-92aa-d57d44560fc9",
   "metadata": {},
   "source": [
    "## **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b214fe4-4328-4752-b55d-801b9394ea8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import PyPDF2\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f26d8-17e8-4eb0-a915-af8f174a0428",
   "metadata": {},
   "source": [
    "## **Environment variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d214cb12-60ec-410a-91d3-b57f3c92d47b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHROMA_DATA_PATH = r\"./embeddings_database\"\n",
    "DATA_DIR = r\"./data\"\n",
    "COLLECTION_NAME = \"LLM-Test-Instadeep\"\n",
    "\n",
    "EMBED_MODEL = \"allenai/scibert_scivocab_uncased\"\n",
    "\n",
    "EMBED_FUNCTION = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "     model_name=EMBED_MODEL\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1608fd-d65e-4977-bdc9-858d4b90c93f",
   "metadata": {},
   "source": [
    "# **Vector database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2b5f678-dc2e-4318-b13a-6db8ec23d719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path = CHROMA_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d41fae8-accc-443e-bc6a-5b4572840b96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collection = client.create_collection(name=COLLECTION_NAME,\n",
    "                                      embedding_function = EMBED_FUNCTION,\n",
    "                                      metadata={\"hnsw:space\": \"cosine\"},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "838bb2e3-e5b8-44a2-b12e-8f16c07810cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Collect all PDF files within the directory and its subdirectories\n",
    "pdf_files = []\n",
    "for root, _, files in os.walk(DATA_DIR):\n",
    "    for file in files:\n",
    "        if file.endswith(\".pdf\"):\n",
    "            pdf_files.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83662bc1-d5cb-46bc-bee2-315c464f6069",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:21<00:00,  2.38s/it]\n"
     ]
    }
   ],
   "source": [
    "loaded_documents = []\n",
    "documents_metadata = []\n",
    "\n",
    "for file in tqdm(pdf_files):    \n",
    "    with open(file, \"rb\") as f:\n",
    "        pdf_reader = PyPDF2.PdfReader(f)\n",
    "        meta = pdf_reader.metadata\n",
    "        \n",
    "        text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "        loaded_documents.append(text)\n",
    "        if meta.title:\n",
    "            title = meta.title\n",
    "        else:\n",
    "            title = \"\"\n",
    "        documents_metadata.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18478e98-6ec8-4b9c-b930-d6ff296f8a84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collection.add(\n",
    "     documents=loaded_documents,\n",
    "     ids=[f\"id{i}\" for i in range(len(loaded_documents))],\n",
    "     metadatas=[{\"title\": t} for t in documents_metadata]\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b97d26-ffce-4c6e-92ff-70fb0abbc0bb",
   "metadata": {},
   "source": [
    "# **Papers Recommendation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfd324f-117c-4d22-aa43-1d1241c5a417",
   "metadata": {},
   "source": [
    "## **Method 1**: ChromaDB similarity search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11857fa-82bd-4638-a1e3-c88d68afa5af",
   "metadata": {},
   "source": [
    "We can use the classic querying methods to fetch information from any kind of database, we can even include special filters to get precise results. ChromaDB provides us with the ability to perform similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb03d164-2fb7-47ba-a281-1542e1256eda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collection = client.get_collection(name=COLLECTION_NAME, embedding_function=EMBED_FUNCTION)\n",
    "\n",
    "similar_papers = collection.query(\n",
    "query_texts=[\"\"\"\n",
    "mRNA vaccines are a type of vaccine that use a copy of a molecule called messenger RNA (mRNA) to produce an immune response1.\n",
    "The vaccine delivers molecules of antigen-encoding mRNA into immune cells, which use the designed mRNA as a blueprint to build foreign protei\n",
    "n that would normally be produced by a pathogen (such as a virus) or by a cancer cell1. These protein molecules stimulate an adaptive immune response \n",
    "that teaches the body to identify and destroy the corresponding pathogen or cancer cells1. The mRNA is delivered by a co-formulation of the RNA encapsulated \n",
    "in lipid nanoparticles that protect the RNA strands and help their absorption into the cells1. mRNA vaccines have attracted considerable interest as COVID-19\n",
    "vaccines1. In December 2020, Pfizer–BioNTech and Moderna obtained authorization for their mRNA-based COVID-19 vaccines1. The 2023 Nobel Prize in Physiology \n",
    "or Medicine was awarded to Katalin Karikó and Drew Weissman for the development of effective mRNA vaccines against COVID-191.\n",
    "\"\"\"],\n",
    "n_results=3,\n",
    "include=[\"documents\",\"metadatas\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035be3f5-9803-4e8f-a0ae-c8502b0fb8d0",
   "metadata": {},
   "source": [
    "## **Method 2**: LangChain retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ae6df1-1087-4b76-8ffc-ecb1d339b9f3",
   "metadata": {},
   "source": [
    "This method consists of using the LangChain wrapper of chromaDB called Chroma to link the vector database with this framework and use retievers to fetch information and perform a similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3287e8e4-cc2f-44a7-99b5-450e5c554def",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(CHROMA_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cd3673-c5ff-49f8-9fca-17b9937852e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "                model_name=\"allenai/scibert_scivocab_uncased\",\n",
    "                model_kwargs={\"device\": \"cpu\"},\n",
    "            )\n",
    "\n",
    "langchain_chroma = Chroma(\n",
    "    client=client,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embedding_function=huggingface_embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "956c7815-e590-4774-b8c3-bed9e4e7624d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9 in the collection\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", langchain_chroma._collection.count(), \"in the collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb4b2725-b022-44c0-a17c-6673bf5092e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = langchain_chroma.as_retriever(search_kwargs={\"k\": 3}, search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb290f79-ab89-4d14-8d70-17a58c6c2e05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "mRNA vaccines are a type of vaccine that use a copy of a molecule called messenger RNA (mRNA) to produce an immune response1.\n",
    "The vaccine delivers molecules of antigen-encoding mRNA into immune cells, which use the designed mRNA as a blueprint to build foreign protei\n",
    "n that would normally be produced by a pathogen (such as a virus) or by a cancer cell1. These protein molecules stimulate an adaptive immune response \n",
    "that teaches the body to identify and destroy the corresponding pathogen or cancer cells1. The mRNA is delivered by a co-formulation of the RNA encapsulated \n",
    "in lipid nanoparticles that protect the RNA strands and help their absorption into the cells1. mRNA vaccines have attracted considerable interest as COVID-19\n",
    "vaccines1. In December 2020, Pfizer–BioNTech and Moderna obtained authorization for their mRNA-based COVID-19 vaccines1. The 2023 Nobel Prize in Physiology \n",
    "or Medicine was awarded to Katalin Karikó and Drew Weissman for the development of effective mRNA vaccines against COVID-191.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1e14183-c0d0-4525-9ea6-09773c8e7e65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea230ef-5550-40fc-92c8-4b41e53c06da",
   "metadata": {},
   "source": [
    "# **Paper Summarization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb2542d-8981-423b-b72a-48891c8b0326",
   "metadata": {},
   "source": [
    "There are 3 methods we can use to summarize papers:\n",
    "* Stuff: utilizes a simpler approach known as stuffing. In this approach, the prompt passes all the related data as context to the language model. While this approach works well for smaller pieces of data, it becomes impractical when dealing with many pieces of data.\n",
    "\n",
    "Since the scientific papers are large documents, we cannot use the Stuff chain, instead, we can use:\n",
    "* Map-reduce: is designed to handle document processing by breaking a large document into smaller, manageable chunks. This chain employs an initial prompt on each piece to generate a summary or answer based on that specific section of the document.\n",
    "\n",
    "* Refine: The ‘refine’ chain involves an initial prompt on the first chunk of data, generating an output. The language model refines the output based on the new document by passing along this output with the next document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2372ff1b-bf3a-47be-909f-e89143646a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e0ca4c7-2b2d-4071-8adc-e3f5b3a9f894",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = r\"./data/raw-pdf_Efficacy and Safety of the mRNA-1273 SARS-CoV-2 Vaccine.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(file)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2accbf05-1d9f-4ab2-a5be-e4278bf0d34d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=20)\n",
    "chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65369fed-387f-4b74-9ba7-5f31c0334e60",
   "metadata": {},
   "source": [
    "## **Method 1**: Map-reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ca0ccf75-4881-48ae-b977-2fd1ea414995",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type='map_reduce',\n",
    "    verbose=False\n",
    ")\n",
    "summary = chain.run(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1c7335ad-3200-46ac-a989-7769bb0a3329",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This article discusses the results of a phase 3 clinical trial for the mRNA-1273 vaccine, which showed an efficacy of 94.1% in preventing Covid-19 illness. The vaccine was generally safe, with only transient reactions reported. The study was funded by the Biomedical Advanced Research and Development Authority and the National Institute of Allergy and Infectious Diseases. The article also provides information on the trial design, participant eligibility criteria, and the blinding of data. It emphasizes the importance of vaccine development during a pandemic and the need for diverse clinical trial populations.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912d1e55-91be-4678-abce-cfd96b407765",
   "metadata": {},
   "source": [
    "## **Method 2**: Refine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38227792-b031-4828-8c12-68ad6b18d7b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "This method takes a long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c36d629d-ad6b-413b-94b3-e1379ba297ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type='refine',\n",
    "    verbose=False\n",
    ")\n",
    "summary = chain.run(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "549a377b-bdac-42bd-aef5-9f31e87a306c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This article discusses the results of a phase 3 clinical trial for the mRNA-1273 vaccine, a lipid nanoparticle–encapsulated mRNA-based vaccine for preventing Covid-19. The trial involved 30,420 participants who were randomly assigned to receive either the vaccine or a placebo. The results showed that the vaccine had an efficacy of 94.1% in preventing Covid-19 illness, including severe cases. The vaccine was generally safe, with only transient local and systemic reactions reported as side effects. The trial assessed the efficacy of the mRNA-1273 vaccine in preventing symptomatic Covid-19 with onset at least 14 days after the second injection. The vaccine demonstrated consistent efficacy across various age groups and risk categories, including age groups of 18 to <65 years. The study was funded by the Biomedical Advanced Research and Development Authority and the National Institute of Allergy and Infectious Diseases. The safety analysis showed that the vaccine had more injection-site and systemic adverse events compared to the placebo group, but these events were generally mild and resolved within a few days. The solicited adverse events were more common among younger participants and less common in participants who were positive for SARS-CoV-2 antibodies. The trial also found that the vaccine had a high efficacy in preventing severe cases of Covid-19, with no severe cases reported among vaccinated participants. The trial data also showed that the vaccine had an incidence rate of 56.5 per 1000 person-years, compared to 79.7 per 1000 person-years for the placebo group. The vaccine demonstrated an efficacy of 94.1% in preventing Covid-19 illness, with a 95% confidence interval of 89.3% to 96.8%. The trial provides evidence of short-term efficacy of the mRNA-1273 vaccine in preventing symptomatic SARS-CoV-2 infection in a diverse adult trial population. The trial was not designed to evaluate the efficacy of a single dose, and additional evaluation is warranted. The safety of the mRNA-1273 vaccine regimen and platform is reassuring, with no unexpected patterns of concern identified. Reactogenicity associated with immunization with mRNA-1273 was similar to that in previous phase 1 data, with mild local reactions and transient moderate-to-severe systemic side effects. The efficacy of mRNA-1273 is higher than that observed for vaccines for respiratory viruses, and longitudinal follow-up will allow an assessment of efficacy changes over time and under evolving epidemiologic conditions. The article was downloaded from nejm.org on August 3, 2023, and is for personal use only. The trial also found that the vaccine did not show evidence of enhanced respiratory disease after infection, and no acute hypersensitivity risk was evident. However, there was a slight excess of Bell's palsy reported, which requires close monitoring. The trial has some limitations, including the short duration of safety and efficacy follow-up, and the lack of an identified correlate of protection. The trial is ongoing, with a planned follow-up duration of 2 years. The trial also highlighted the importance of collaboration among academia, government, industry, regulators, and the larger community in responding to a pandemic.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caff77c5",
   "metadata": {},
   "source": [
    "# **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "df66e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7fc23adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing summaries from the JSON file\n",
    "with open('summ.json', 'r') as json_file:\n",
    "    existing_summaries = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a7895b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE scores for 'raw-pdf_biomedicines-11-00308-v2.pdf':\n",
      "ROUGE-1: Score(precision=0.5934065934065934, recall=0.5684210526315789, fmeasure=0.5806451612903225)\n",
      "ROUGE-2: Score(precision=0.2111111111111111, recall=0.20212765957446807, fmeasure=0.20652173913043478)\n",
      "ROUGE-L: Score(precision=0.38461538461538464, recall=0.3684210526315789, fmeasure=0.3763440860215054)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 259.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.51 seconds, 1.98 sentences/sec\n",
      "\n",
      "BERTScore for 'raw-pdf_biomedicines-11-00308-v2.pdf':\n",
      "tensor([0.9139])\n",
      "ROUGE scores for 'raw-pdf_82_2020_217.pdf':\n",
      "ROUGE-1: Score(precision=0.5609756097560976, recall=0.5, fmeasure=0.5287356321839081)\n",
      "ROUGE-2: Score(precision=0.2962962962962963, recall=0.26373626373626374, fmeasure=0.2790697674418605)\n",
      "ROUGE-L: Score(precision=0.3902439024390244, recall=0.34782608695652173, fmeasure=0.36781609195402304)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 501.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.46 seconds, 2.17 sentences/sec\n",
      "\n",
      "BERTScore for 'raw-pdf_82_2020_217.pdf':\n",
      "tensor([0.9202])\n",
      "ROUGE scores for 'raw-pdf_Efficacy and Safety of the mRNA-1273 SARS-CoV-2 Vaccine.pdf':\n",
      "ROUGE-1: Score(precision=0.47413793103448276, recall=0.5670103092783505, fmeasure=0.516431924882629)\n",
      "ROUGE-2: Score(precision=0.25217391304347825, recall=0.3020833333333333, fmeasure=0.2748815165876777)\n",
      "ROUGE-L: Score(precision=0.33620689655172414, recall=0.4020618556701031, fmeasure=0.36619718309859156)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 250.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.64 seconds, 1.57 sentences/sec\n",
      "\n",
      "BERTScore for 'raw-pdf_Efficacy and Safety of the mRNA-1273 SARS-CoV-2 Vaccine.pdf':\n",
      "tensor([0.8910])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\", streaming=False)\n",
    "\n",
    "# Iterate through keys (file titles) in the JSON file\n",
    "for file_title in existing_summaries.keys():\n",
    "\n",
    "    # Load the original PDF file based on the file title\n",
    "    file = \"./data/\" + file_title\n",
    "\n",
    "    loader = PyPDFLoader(file)\n",
    "    docs = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=20)\n",
    "    chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "    chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type='map_reduce',\n",
    "    verbose=False )\n",
    "\n",
    "    generated_summary = chain.run(chunks)\n",
    "\n",
    "    # Get the expected summary for the original PDF from the JSON file\n",
    "    expected_summary = existing_summaries[file_title]\n",
    "\n",
    "    # Calculate ROUGE score\n",
    "    rouge_scorer_instance = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge_scores = rouge_scorer_instance.score(generated_summary, expected_summary)\n",
    "\n",
    "    print(f\"ROUGE scores for '{file_title}':\")\n",
    "    print(\"ROUGE-1:\", rouge_scores['rouge1'])\n",
    "    print(\"ROUGE-2:\", rouge_scores['rouge2'])\n",
    "    print(\"ROUGE-L:\", rouge_scores['rougeL'])\n",
    "\n",
    "    # Calculate BERTScore\n",
    "    _, _, bert_scores = score([generated_summary], [expected_summary], lang='en', verbose=True)\n",
    "    \n",
    "    print(f\"\\nBERTScore for '{file_title}':\")\n",
    "    print(bert_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
